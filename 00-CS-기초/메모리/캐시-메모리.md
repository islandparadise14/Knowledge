---
tags: [cs, memory, cache, cpu, performance]
---

# 캐시 메모리

## 💡 핵심 개념

**캐시 메모리**는 CPU와 메인 메모리(RAM) 사이에 위치한 고속 메모리이다. CPU가 자주 사용하는 데이터를 캐시에 복사해두면 RAM까지 가지 않아도 되므로 속도가 빨라진다. L1 > L2 > L3 순으로 속도가 빠르고 용량이 작다.

## 📌 왜 필요한가?

배열이 연결 리스트보다 빠른 이유, 데이터 지역성(Locality)에 따른 성능 차이를 이해할 수 있다. Android에서 LruCache도 캐시 개념의 응용이다.

## 🔍 자세히

### 캐시 계층

```
CPU Core
  │
  ├─ L1 Cache (32~64KB)    ~1ns     가장 빠름
  ├─ L2 Cache (256KB~1MB)  ~4ns
  ├─ L3 Cache (수 MB)      ~10ns    코어 간 공유
  │
RAM (수 GB)                ~100ns    50~100배 느림
  │
Storage (SSD/Flash)        ~μs~ms   훨씬 느림
```

### 데이터 지역성 (Locality)

```kotlin
// 시간 지역성 (Temporal): 최근 접근한 데이터를 다시 접근
for (i in 0 until 100) {
    sum += array[0]  // 같은 위치 반복 접근 → 캐시 히트
}

// 공간 지역성 (Spatial): 인접한 메모리를 접근
for (i in array.indices) {
    sum += array[i]  // 연속 메모리 순차 접근 → 캐시 히트
}
```

### 배열 vs 연결 리스트 (캐시 관점)

```
배열: [1][2][3][4][5] → 연속 메모리 → 캐시 라인에 한 번에 로드 → 빠름
연결리스트: [1]→ ... [2]→ ... [3] → 흩어진 메모리 → 캐시 미스 → 느림
```

### Android에서의 캐시 활용

```kotlin
// LruCache - 메모리 캐시 (최근 사용 항목 유지)
val maxMemory = (Runtime.getRuntime().maxMemory() / 1024).toInt()
val cacheSize = maxMemory / 8

val bitmapCache = object : LruCache<String, Bitmap>(cacheSize) {
    override fun sizeOf(key: String, bitmap: Bitmap): Int {
        return bitmap.byteCount / 1024
    }
}

// 이미지 라이브러리(Glide, Coil)도 내부적으로 메모리/디스크 캐시 사용
```

## 🔗 관련 개념

- [[00-CS-기초/메모리/스택-vs-힙|스택 vs 힙]]
- [[00-CS-기초/자료구조/배열-vs-연결리스트|배열 vs 연결리스트]]
- [[00-CS-기초/메모리/메모리-정렬과-패딩|메모리 정렬과 패딩]]

## 📚 더 보기

- [LruCache 문서](https://developer.android.com/reference/android/util/LruCache)

---

**핵심 요약:** 캐시 메모리는 CPU와 RAM 사이의 고속 버퍼. 배열이 연결 리스트보다 빠른 이유는 공간 지역성 덕분. Android에서 LruCache로 메모리 캐시를 구현한다.
